{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a737dd",
   "metadata": {},
   "source": [
    "# Training on FER+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc1a5d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78458351",
   "metadata": {},
   "source": [
    "### Installation of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f09663",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q tensorflow tensorflow-addons tensorflow-hub tensorflow-datasets matplotlib seaborn scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14c3f6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bde7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import mixed_precision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5a4f5",
   "metadata": {},
   "source": [
    "### Mixed precision and device selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c958ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mixed precision policy\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# use GPU if available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19091a9",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, dataset, num_classes, class_names):\n",
    "    # Get predictions\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    for x, y in dataset:\n",
    "        pred = model.predict(x)\n",
    "        y_pred.extend(np.argmax(pred, axis=1))\n",
    "        y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Normalize confusion matrix\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=class_names if class_names else range(num_classes),\n",
    "                yticklabels=class_names if class_names else range(num_classes))\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Also show raw counts\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names if class_names else range(num_classes),\n",
    "                yticklabels=class_names if class_names else range(num_classes))\n",
    "    plt.title('Confusion Matrix (Raw Counts)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# plot the training history\n",
    "def plot_training_history(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(model, dataset, class_names, num_classes, num_samples=5):\n",
    "    plt.figure(figsize=(15, num_samples*3))\n",
    "    \n",
    "    count = 0\n",
    "    for images, labels in dataset:\n",
    "        for i in range(min(len(images), num_samples - count)):\n",
    "            image = images[i].numpy()\n",
    "            true_label = np.argmax(labels[i].numpy())\n",
    "            \n",
    "            # Make prediction\n",
    "            pred = model.predict(tf.expand_dims(images[i], 0))\n",
    "            pred_label = np.argmax(pred)\n",
    "            \n",
    "            # Display image and predictions\n",
    "            plt.subplot(num_samples, 3, count*3 + 1)\n",
    "            # Convert back to grayscale for visualization\n",
    "            plt.imshow(image[:,:,0], cmap='gray')\n",
    "            plt.title(f\"True: {class_names[true_label]}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(num_samples, 3, count*3 + 2)\n",
    "            plt.bar(range(num_classes), pred[0])\n",
    "            plt.xticks(range(num_classes), class_names, rotation=45)\n",
    "            plt.title(f\"Prediction: {class_names[pred_label]}\")\n",
    "            \n",
    "            plt.subplot(num_samples, 3, count*3 + 3)\n",
    "            plt.text(0.5, 0.5, f\"Confidence: {pred[0][pred_label]:.4f}\\nCorrect: {'✓' if true_label == pred_label else '✗'}\", \n",
    "                    ha='center', fontsize=12)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            count += 1\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "        if count >= num_samples:\n",
    "            break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eda23f",
   "metadata": {},
   "source": [
    "## Data preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfcffc",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/fer2013++.csv')\n",
    "\n",
    "# Use official dataset splits\n",
    "train_df = data[data.Usage=='Training']\n",
    "val_df = data[data.Usage=='PublicTest']    # validation\n",
    "test_df = data[data.Usage=='PrivateTest']  # final report\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06a7b4",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da993ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data['emotion'].value_counts().to_dict()\n",
    "total_samples = len(data)\n",
    "num_classes = 8\n",
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral', 'Contempt']\n",
    "\n",
    "# Inverse frequency weighting\n",
    "class_weights = {class_id: total_samples / (num_classes * count) \n",
    "                for class_id, count in class_counts.items()}\n",
    "print(\"Class weights (inverse frequency):\", class_weights)\n",
    "\n",
    "# Process training data\n",
    "train_pixels = train_df['pixels'].tolist()\n",
    "trainX = np.array([np.fromstring(pixel_sequence, sep=' ') for pixel_sequence in train_pixels])\n",
    "trainX = trainX.reshape((-1, 48, 48, 1))\n",
    "# trainX = trainX / 255.0\n",
    "trainY = to_categorical(train_df['emotion'], num_classes=num_classes)\n",
    "\n",
    "# Process validation data\n",
    "val_pixels = val_df['pixels'].tolist()\n",
    "valX = np.array([np.fromstring(pixel_sequence, sep=' ') for pixel_sequence in val_pixels])\n",
    "valX = valX.reshape((-1, 48, 48, 1))\n",
    "# valX = valX / 255.0\n",
    "valY = to_categorical(val_df['emotion'], num_classes=num_classes)\n",
    "\n",
    "# Process test data\n",
    "test_pixels = test_df['pixels'].tolist()\n",
    "testX = np.array([np.fromstring(pixel_sequence, sep=' ') for pixel_sequence in test_pixels])\n",
    "testX = testX.reshape((-1, 48, 48, 1))\n",
    "# testX = testX / 255.0\n",
    "testY = to_categorical(test_df['emotion'], num_classes=num_classes)\n",
    "\n",
    "print(f\"Train shape: {trainX.shape}, {trainY.shape}\")\n",
    "print(f\"Validation shape: {valX.shape}, {valY.shape}\")\n",
    "print(f\"Test shape: {testX.shape}, {testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ab1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x, y):\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_brightness(x, 25)\n",
    "    x = tf.image.random_contrast(x, 0.8, 1.2)\n",
    "    return x, y\n",
    "\n",
    "def preprocess_image(x, y):\n",
    "    x = tf.image.resize(x, (224,224))\n",
    "    x = tf.image.grayscale_to_rgb(x)\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)  # 0-255 –> [-1,1]\n",
    "    return x, y\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
    "            .shuffle(len(trainX))\n",
    "            .map(augment,  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size=batch_size).prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "val_dataset   = (tf.data.Dataset.from_tensor_slices((valX, valY))\n",
    "            .map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size=batch_size).prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "test_dataset  = (tf.data.Dataset.from_tensor_slices((testX, testY))\n",
    "            .map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size=batch_size).prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape must match MobileNetV2 expectations\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e63aa",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(192, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72816812",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a4587",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01495b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=15,\n",
    "                    class_weight=class_weights,\n",
    "                    callbacks=[reduce_lr])\n",
    "\n",
    "print(\"Training history for base model:\")\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d9d05",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a968e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
    "\n",
    "checkpoint_finetune = ModelCheckpoint(\n",
    "    'best_finetune_06.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_finetune = model.fit(train_dataset, \n",
    "                            validation_data=val_dataset,\n",
    "                            epochs=30,\n",
    "                            class_weight=class_weights,\n",
    "                            callbacks=[reduce_lr, ])\n",
    "\n",
    "model.save('finetune_06.keras')\n",
    "\n",
    "print(\"Training history for finetune model:\")\n",
    "plot_training_history(history_finetune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed01c94",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "print(\"Evaluating the model on test dataset:\")\n",
    "\n",
    "# Load fine-tuned model\n",
    "finetune = tf.keras.models.load_model('finetune_06.keras')\n",
    "test_loss_finetune, test_accuracy_finetune = finetune.evaluate(test_dataset)\n",
    "print(f\"Fine-tuned model test loss: {test_loss_finetune}, Fine-tuned model test accuracy: {test_accuracy_finetune}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix for all three models on test dataset\n",
    "print(\"Confusion Matrix for Fine-tuned Model (Test Set):\")\n",
    "cm, cm_norm = plot_confusion_matrix(finetune, test_dataset, num_classes, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f8ace",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eaa416",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nVisualizing predictions for the model:\")\n",
    "visualize_predictions(model, val_dataset, class_names, num_classes=num_classes, num_samples=10)\n",
    "\n",
    "#Calculate per-class accuracy\n",
    "per_class_acc = np.diag(cm_norm)\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for i, (class_name, acc) in enumerate(zip(class_names, per_class_acc)):\n",
    "    print(f\"{class_name}: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
